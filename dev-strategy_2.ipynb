{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import faiss\n",
    "import os\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "EMBEDER_KEY = os.getenv('EMBEDER_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prepared_data_frame.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_storage(id_series: pd.Series, data_series: pd.Series):\n",
    "    '''Функция парсит данные из датасета, собирая в JSON БД\n",
    "    \n",
    "    Args:\n",
    "        id_series - столбец датасета с идентификатором документа\n",
    "        data_series - стобец датасета с чанками\n",
    "    Output:\n",
    "        JSON БД\n",
    "    '''\n",
    "    storage = {}\n",
    "    key_id = 0\n",
    "\n",
    "    for row_num in range(len(data_series)):\n",
    "        id_doc = id_series[row_num]\n",
    "        data_document = data_series[row_num]\n",
    "\n",
    "        for document in data_document:\n",
    "            # Проверка на дополнительную вложенность\n",
    "            if isinstance(document, list):\n",
    "                for chunk in document:\n",
    "\n",
    "                    storage[key_id] = (id_doc, chunk)\n",
    "                    key_id += 1\n",
    "            else:\n",
    "                storage[key_id] = (id_doc, document)\n",
    "                key_id += 1\n",
    "\n",
    "    print(f\"Storage ready, key from 0 to {key_id-1}\")\n",
    "\n",
    "    return storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    # Подключаемся к модели\n",
    "    client = OpenAI(\n",
    "        # Базовый url - сохранять без изменения\n",
    "        base_url=\"https://ai-for-finance-hack.up.railway.app/\",\n",
    "        # Указываем наш ключ, полученный ранее\n",
    "        api_key=EMBEDER_KEY,\n",
    "    )\n",
    "    # Формируем запрос к клиенту\n",
    "    response = client.embeddings.create(\n",
    "        # Выбираем любую допступную модель из предоставленного списка\n",
    "        model=\"text-embedding-3-small\",\n",
    "        # Отправяем запрос\n",
    "        input=text, \n",
    "        # Определяем размерность эмбединга\n",
    "        dimensions = 512\n",
    "    )\n",
    "    # Формируем ответ на запрос и возвращаем его в результате работы функции\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_embeddings(texts, batch_size=32, dimensions=512):\n",
    "    \"\"\"Батчевые запросы к embedding API\n",
    "\n",
    "    Args:\n",
    "        texts: список строк\n",
    "        batch_size: количество текстов в одном запросе\n",
    "        dimensions: размерность эмбединга\n",
    "    Returns:\n",
    "        Список эмбеддингов (list[list[float]]).\n",
    "    \"\"\"\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://ai-for-finance-hack.up.railway.app/\",\n",
    "        api_key=EMBEDER_KEY,\n",
    "    )\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=batch,            \n",
    "            dimensions=dimensions\n",
    "        )\n",
    "\n",
    "        # каждая запись в response.data соответствует одному элементу из batch\n",
    "        batch_embeddings = [item.embedding for item in response.data]\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(embedding: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes a given vector to have unit length.\n",
    "\n",
    "    Args:\n",
    "        embedding (np.ndarray): A NumPy array representing the vector to normalize.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A normalized vector with unit length.\n",
    "    \"\"\"\n",
    "\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    if abs(norm) >= 1e-9: #защита от взрыва и погрешности\n",
    "      embedding /= norm\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build an HNSW index\n",
    "def build_faiss_hnsw_index(dimension, ef_construction=200, M=32):\n",
    "    \"\"\"\n",
    "    build_faiss_hnsw_index: Add a description here.\n",
    "\n",
    "    Args:\n",
    "        # List the arguments with types and descriptions.\n",
    "\n",
    "    Returns:\n",
    "        # Specify what the function returns.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Builds a FAISS HNSW index for cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "        dimension (int): Dimensionality of the embeddings.\n",
    "        ef_construction (int): Trade-off parameter between index construction speed and accuracy.\n",
    "        M (int): Number of neighbors in the graph.\n",
    "\n",
    "    Returns:\n",
    "        index (faiss.IndexHNSWFlat): Initialized FAISS HNSW index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexHNSWFlat(dimension, M)  # HNSW index\n",
    "    index.hnsw.efConstruction = ef_construction  # Construction accuracy\n",
    "    index.metric_type = faiss.METRIC_INNER_PRODUCT  # Cosine similarity via normalized vectors\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to populate the FAISS index\n",
    "def populate_faiss_index(index: faiss.Index, documents: dict, batch_size: int=20):\n",
    "    \"\"\"\n",
    "    populate_faiss_index: Add a description here.\n",
    "\n",
    "    Args:\n",
    "        # List the arguments with types and descriptions.\n",
    "\n",
    "    Returns:\n",
    "        # Specify what the function returns.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Populates the FAISS HNSW index with normalized embeddings from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        index (faiss.Index): FAISS index to populate.\n",
    "        documents (pd.Series): documents like List[list[str]]\n",
    "        batch_size (int): Number of questions to process at a time.\n",
    "    \"\"\"\n",
    "    buffer = []\n",
    "    i = 0\n",
    "\n",
    "    for _, embedding in documents.items():\n",
    "        embedding = normalize_vector(embedding)\n",
    "        buffer.append(embedding)\n",
    "        i += 1\n",
    "\n",
    "        # Add embeddings to the index in batches\n",
    "        if len(buffer) >= batch_size:\n",
    "            index.add(np.array(buffer, dtype=np.float32))\n",
    "            buffer = []\n",
    "\n",
    "    # Add remaining embeddings\n",
    "    if buffer:\n",
    "        index.add(np.array(buffer, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform a search query\n",
    "def search_faiss_index(embeddings_storage, query, k=5):\n",
    "    \"\"\"\n",
    "    search_faiss_index: Add a description here.\n",
    "\n",
    "    Args:\n",
    "        # List the arguments with types and descriptions.\n",
    "\n",
    "    Returns:\n",
    "        # Specify what the function returns.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Searches the FAISS index for the closest matches to a query.\n",
    "\n",
    "    Parameters:\n",
    "        embeddings_storage (faiss.Index): FAISS index to search.\n",
    "        query (str): Query string to search.\n",
    "        k (int): Number of closest matches to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        indices (np.ndarray): Indices of the top-k results.\n",
    "        distances (np.ndarray): Distances of the top-k results.\n",
    "    \"\"\"\n",
    "    # Preprocess and normalize the query embedding\n",
    "    query_embedding = get_embedding(query)\n",
    "    query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "    query_embedding = normalize_vector(query_embedding)\n",
    "    # Search the embeddings_storage\n",
    "    top_k_distances, top_k_indices = embeddings_storage.search(np.array([query_embedding], dtype=np.float32), k)\n",
    "\n",
    "    # Match return format with that used in numpy storage search\n",
    "    # Note that list manipulations will give an overhead\n",
    "    top_k_indices_list = top_k_indices[0].tolist()\n",
    "    top_k_distances_list = top_k_distances[0].tolist()\n",
    "\n",
    "    return top_k_indices_list, top_k_distances_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка json БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotation</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation_tags_chunk</th>\n",
       "      <th>text_chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_001</td>\n",
       "      <td>Светлана из Казани дает частные уроки английск...</td>\n",
       "      <td>Начать бизнес, Самозанятые, Свое дело, Налоги</td>\n",
       "      <td>[(Кто такой самозанятый?, По закону самозаняты...</td>\n",
       "      <td>[Начать бизнес, Самозанятые, Свое дело, Налоги...</td>\n",
       "      <td>[[Кто такой самозанятый?По закону самозанятый ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_002</td>\n",
       "      <td>Елене назначили социальное пособие на ребенка,...</td>\n",
       "      <td>Защитить права, Банки, Банковская карта, Риски...</td>\n",
       "      <td>[(, Первым делом нужно попросить банк проверит...</td>\n",
       "      <td>[Защитить права, Банки, Банковская карта, Риск...</td>\n",
       "      <td>[[Первым делом нужно попросить банк проверить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_003</td>\n",
       "      <td>Самый надежный способ не оказаться в долгах — ...</td>\n",
       "      <td>Кредиты, Долги, Просрочки, Ипотека, Кредитная ...</td>\n",
       "      <td>[(, Не переоценивайте свои финансовые возможно...</td>\n",
       "      <td>[Кредиты, Долги, Просрочки, Ипотека, Кредитная...</td>\n",
       "      <td>[[Не переоценивайте свои финансовые возможност...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_004</td>\n",
       "      <td>Друзья Александра то и дело хвастаются, что по...</td>\n",
       "      <td>Инвестиции, Ценные бумаги, Фондовая биржа, Акц...</td>\n",
       "      <td>[(, Просто прийти на биржу и купить ценные бум...</td>\n",
       "      <td>[Инвестиции, Ценные бумаги, Фондовая биржа, Ак...</td>\n",
       "      <td>[[Просто прийти на биржу и купить ценные бумаг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc_005</td>\n",
       "      <td>Вы взяли в микрофинансовой организации заем на...</td>\n",
       "      <td>Займы, Долги, Риски, Защитить права</td>\n",
       "      <td>[(МФО больше нет в госреестре. Значит, она зак...</td>\n",
       "      <td>[Займы, Долги, Риски, Защитить права. Вы взяли...</td>\n",
       "      <td>[[МФО больше нет в госреестре. Значит, она зак...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                         annotation  \\\n",
       "0  doc_001  Светлана из Казани дает частные уроки английск...   \n",
       "1  doc_002  Елене назначили социальное пособие на ребенка,...   \n",
       "2  doc_003  Самый надежный способ не оказаться в долгах — ...   \n",
       "3  doc_004  Друзья Александра то и дело хвастаются, что по...   \n",
       "4  doc_005  Вы взяли в микрофинансовой организации заем на...   \n",
       "\n",
       "                                                tags  \\\n",
       "0      Начать бизнес, Самозанятые, Свое дело, Налоги   \n",
       "1  Защитить права, Банки, Банковская карта, Риски...   \n",
       "2  Кредиты, Долги, Просрочки, Ипотека, Кредитная ...   \n",
       "3  Инвестиции, Ценные бумаги, Фондовая биржа, Акц...   \n",
       "4                Займы, Долги, Риски, Защитить права   \n",
       "\n",
       "                                                text  \\\n",
       "0  [(Кто такой самозанятый?, По закону самозаняты...   \n",
       "1  [(, Первым делом нужно попросить банк проверит...   \n",
       "2  [(, Не переоценивайте свои финансовые возможно...   \n",
       "3  [(, Просто прийти на биржу и купить ценные бум...   \n",
       "4  [(МФО больше нет в госреестре. Значит, она зак...   \n",
       "\n",
       "                               annotation_tags_chunk  \\\n",
       "0  [Начать бизнес, Самозанятые, Свое дело, Налоги...   \n",
       "1  [Защитить права, Банки, Банковская карта, Риск...   \n",
       "2  [Кредиты, Долги, Просрочки, Ипотека, Кредитная...   \n",
       "3  [Инвестиции, Ценные бумаги, Фондовая биржа, Ак...   \n",
       "4  [Займы, Долги, Риски, Защитить права. Вы взяли...   \n",
       "\n",
       "                                          text_chunk  \n",
       "0  [[Кто такой самозанятый?По закону самозанятый ...  \n",
       "1  [[Первым делом нужно попросить банк проверить ...  \n",
       "2  [[Не переоценивайте свои финансовые возможност...  \n",
       "3  [[Просто прийти на биржу и купить ценные бумаг...  \n",
       "4  [[МФО больше нет в госреестре. Значит, она зак...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage ready, key from 0 to 369\n"
     ]
    }
   ],
   "source": [
    "storage_an_t = data_to_storage(\n",
    "        id_series = data['id'],\n",
    "        data_series = data['annotation_tags_chunk']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Получаем эмбединги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем текст для батчевого запроса\n",
    "texts = list()\n",
    "for _, val in storage_an_t.items():\n",
    "    texts.append(val[1])\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запрос к openrouter\n",
    "embeddings = get_batch_embeddings(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем временное хранилище векторов\n",
    "embed_storage_an_t = dict()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    embed_storage_an_t[i] = np.array(embeddings[i], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512,), 370)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размерность полученных эмбедингов\n",
    "embed_storage_an_t[0].shape, len(embed_storage_an_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Инициализируем Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions of the embedding vectors\n",
    "embedding_dimension = 512  # Depends on the FastText model\n",
    "\n",
    "# Build the HNSW index\n",
    "hnsw_index_an_t = build_faiss_hnsw_index(embedding_dimension)\n",
    "\n",
    "# Populate the index from pd.Series\n",
    "populate_faiss_index(index=hnsw_index_an_t, documents=embed_storage_an_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                 doc_003\n",
       "annotation               Самый надежный способ не оказаться в долгах — ...\n",
       "tags                     Кредиты, Долги, Просрочки, Ипотека, Кредитная ...\n",
       "text                     [(, Не переоценивайте свои финансовые возможно...\n",
       "annotation_tags_chunk    [Кредиты, Долги, Просрочки, Ипотека, Кредитная...\n",
       "text_chunk               [[Не переоценивайте свои финансовые возможност...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовый поиск по annotation\n",
    "correct_id = 2 # рандомный идентификатор для примера annotation \n",
    "example = get_embedding(text=data.loc[correct_id, 'annotation']) # По тексту annotation получаем эмбединг\n",
    "example = normalize_vector(example)\n",
    "\n",
    "top_k_indices, top_k_similarities = hnsw_index_an_t.search(np.array([example], dtype=np.float32), 1) # В БД Tags+annotation ищем пример\n",
    "\n",
    "assert correct_id == top_k_similarities.item(), 'Что то не работает =('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовый поиск по tags\n",
    "correct_id = 2 # рандомный идентификатор для примера annotation \n",
    "example = get_embedding(text=data.loc[correct_id, 'tags']) # По тексту tags получаем эмбединг\n",
    "example = normalize_vector(example)\n",
    "\n",
    "top_k_indices, top_k_similarities = hnsw_index_an_t.search(np.array([example], dtype=np.float32), 10) # В БД Tags+annotation ищем пример\n",
    "\n",
    "assert correct_id in top_k_similarities[0], 'Что то не работает =('"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raif_hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
